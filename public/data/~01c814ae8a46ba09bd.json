{"id":"~01c814ae8a46ba09bd","title":"Python\/Go script to scrape websites in parallel","snippet":"Looking for Python Script using asyncio (https:\/\/docs.python.org\/dev\/library\/asyncio.html) or Go.\n\nGiven a list of x URLs (let\u2019s test with 100k with all different domains)\n\n- Program that would fetch these URL in parallel (it will not crawl\/follow any links, just the URL provided)\n- It\u2019s possible that some of these URL are unreachable or the domains do not resolve to anything.  Note these dead URL and the reason they are dead\n- If these are reachable, capture the following information:\n\n          IP address of the URL\n          Get the title\n          Run a series of regex matches to be provided\n          Fetch a list of resources\n\n          save the html locally\n          save all these data into a json file\n          push these into a database (optional)\n\nParameter: use as little RAM as possible.  Planning to run these on 512MB-1GB VM\u2019s so the ability to run as many thread\/processes as possible would ensure maximum throughput.\n","category2":"Web, Mobile & Software Dev","subcategory2":"Scripts & Utilities","skills":["data-scraping","web-scraping"],"job_type":"Fixed","budget":300,"duration":null,"workload":null,"job_status":"Open","date_created":"2016-10-27T06:00:08+0000","url":"http:\/\/www.upwork.com\/jobs\/~01c814ae8a46ba09bd","client":{"country":"United States","feedback":0,"reviews_count":0,"jobs_posted":1,"past_hires":0,"payment_verification_status":null}}